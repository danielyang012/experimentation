{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Commerce/Growth Marketing Sample Size Calculator\n",
        "\n",
        "**Overview:**\n",
        "\n",
        "This program conducts a sensitivity analysis based on test design parameters to output sample sizes needed and time-to-complete testing in csv format. Users can specify a range of values to conduct power analysis on for hypothesis testing involving differences in means (t-test) and differences in proportions (z-test).\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.   Input test design parameters in \"Test Design Parameters\"\n",
        "2.   Go to Runtime and Run All\n",
        "3.   See auto-generated spreadsheet in File tab!\n",
        "\n",
        "\n",
        "**Parameter Definitions:**\n",
        "\n",
        "*   test_type = determines if you are testing a difference in proportions or a difference in means\n",
        "*   desired_alpha = the statistical significance level you would like for your test (Probability of Type 1 Error)\n",
        "*   desired_stat_power = the statistical power you would like for your test (1 - Probability of Type 2 Error)\n",
        "*   number_of_groups = # of groups that will be in your experiment, including control group (minimum of 2; 1 treatment and 1 control)\n",
        "*   metric_name = name of metric you are conducting power analysis for; used for naming output csv\n",
        "*   mde_relative_lower_bound_percent = minimum detectable effect lower bound you would like to conduct sensitivity analysis on, expressed as a percent relative lift. For example: input of .5 equals .5%\n",
        "*   mde_relative_upper_bound_percent = minimum detectable effect upper bound you would like to conduct sensitivity analysis on, expressed as a percent relative lift. For example: input of 1 equals 1%\n",
        "*   mde_relative_step_percent = step size you would like between lower and upper bound for sensitivity analysis. For example: input of 0.3 equals 0.3%\n",
        "\n",
        "*   baseline_stat = baseline proportion for proportions or baseline mean for means\n",
        "*   baseline_standard_deviation = baseline standard deviation, used only for testing difference of means (test_type = means)\n",
        "*  expected_total_weekly_traffic = total weekly traffic we expect to receive for our experiment (inclusive of control and treatment groups)\n",
        "\n",
        "\n",
        "**Notes:**\n",
        "*   Calculations assume even traffic split of expected_total_weekly_traffic across number_of_groups. For cases where we expect to allocate only a portion of expected_total_weekly_traffic, please adjust your expected_total_weekly_traffic input accordingly\n",
        "\n",
        "\n",
        "*   This program utilizes the following methods to calculate sample size: https://www.statsmodels.org/stable/generated/statsmodels.stats.power.tt_ind_solve_power.html\n",
        "https://www.statsmodels.org/stable/generated/statsmodels.stats.power.zt_ind_solve_power.html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-02wXzSvqZ7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Test Design Parameters { run: \"auto\", vertical-output: true, form-width: \"50%\", display-mode: \"both\" }\n",
        "test_type = \"proportions\" # @param [\"proportions\", \"means\"]\n",
        "desired_stat_power = 0.8 # @param {type:\"slider\", min:0.6, max:1, step:0.025}\n",
        "\n",
        "desired_alpha = 0.1 # @param {type:\"slider\", min:0.01, max:0.50, step:0.005}\n",
        "number_of_groups = 2 # @param {type:\"slider\", min:2, max:15, step:1}\n",
        "metric_name = 'roadblock conversion rate' #@param {type:\"string\"}\n",
        "\n",
        "mde_relative_lower_bound_percent = .25 # @param {type:\"number\"}\n",
        "mde_relative_upper_bound_percent = 3 # @param {type:\"number\"}\n",
        "mde_relative_step_percent = .25 # @param {type:\"number\"}\n",
        "\n",
        "baseline_stat_lower_bound = .135 # @param {type:\"number\"}\n",
        "baseline_stat_upper_bound = .16 # @param {type:\"number\"}\n",
        "baseline_stat_step = 0.01 # @param {type:\"number\"}\n",
        "\n",
        "baseline_standard_deviation = 1.5 # @param {type:\"number\"}\n",
        "\n",
        "expected_total_weekly_traffic = 133538 # @param {type:\"number\"}\n"
      ],
      "metadata": {
        "id": "NOvR7GS9CRa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOnuSheG1ERO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f5bf43-a904-40af-f2f4-b425831bfeb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "It looks like we have our test design parameters all set, let's conduct our sample sizing sensitivity analysis!\n",
            "\n",
            "Analysis completed! Please see csv for required sample size  for each group and weeks-to-test. \n",
            "\n",
            "    Note: This program utilizes a two sample z-test for differences in proportions and a two sample t-test for a difference in means\n",
            "\n",
            "Execution time: 0:00:00.691406\n"
          ]
        }
      ],
      "source": [
        "# @title Function Definitions and Calls\n",
        "# import packages and necessary functions\n",
        "import timeit\n",
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from datetime import datetime\n",
        "from statsmodels.stats.power import tt_ind_solve_power, zt_ind_solve_power\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "\n",
        "current_d = str(datetime.now())\n",
        "current_d = current_d[:current_d.find('.')]\n",
        "np.random.seed(42)\n",
        "\n",
        "# function to check user parameters to make sure they are valid.\n",
        "def validate_test_parameters():\n",
        "  is_valid = True\n",
        "  # make sure upper bound is greater than lower bound\n",
        "  if mde_relative_lower_bound_percent > mde_relative_upper_bound_percent:\n",
        "    print(\"ERROR: Your mde_relative_lower_bound_percent is greater than your mde_relative_upper_bound_percent\")\n",
        "    is_valid = False\n",
        "    #make sure step size + lower bound is not greater upper bound\n",
        "  elif mde_relative_lower_bound_percent + mde_relative_step_percent > mde_relative_upper_bound_percent:\n",
        "    print(\"ERROR: Your mde_relative_step_percent is too high\")\n",
        "    is_valid = False\n",
        "  if baseline_stat_lower_bound > baseline_stat_upper_bound:\n",
        "    print(\"ERROR: Your baseline_stat_lower_bound is greater than your baseline_stat_upper_bound\")\n",
        "    is_valid = False\n",
        "  elif baseline_stat_lower_bound + baseline_stat_step > baseline_stat_upper_bound:\n",
        "    print(\"ERROR: Your baseline_stat_step is too high\")\n",
        "    is_valid = False\n",
        "  if baseline_stat_step <= 0:\n",
        "    print(\"ERROR: Your baseline_stat_step is not greater than 0\")\n",
        "    is_valid = False\n",
        "  if mde_relative_step_percent <= 0:\n",
        "    print(\"ERROR: Your mde_relative_step_percent is not greater than 0\")\n",
        "    is_valid = False\n",
        "  # make sure expected total_weekly_traffic is greater than 0\n",
        "  if expected_total_weekly_traffic <= 0:\n",
        "    print(\"ERROR: Your expected total weekly traffic is not greater than 0\")\n",
        "    is_valid = False\n",
        "  return(is_valid)\n",
        "\n",
        "#generator function to create ranges for sensitivity analysis\n",
        "def frange(x,y,jump):\n",
        "  while x <= y+ jump:\n",
        "    yield round(x,7)\n",
        "    x+= jump\n",
        "\n",
        "# takes in a dictionary of test design parameters and a validated test parameter boolean and returns a mde-sensitivy analysis in csv format of sample sizes\n",
        "def sample_size(vtp_boolean):\n",
        "  if vtp_boolean == False:\n",
        "    print(\"\\nExiting program, please re-run with valid parameters\")\n",
        "    pass\n",
        "  else:\n",
        "    print(\"\\nIt looks like we have our test design parameters all set, let's conduct our sample sizing sensitivity analysis!\")\n",
        "    set_alpha = desired_alpha\n",
        "    mde_list = list(frange(mde_relative_lower_bound_percent, mde_relative_upper_bound_percent, mde_relative_step_percent))\n",
        "    baseline_stat_list = list(frange(baseline_stat_lower_bound, baseline_stat_upper_bound, baseline_stat_step))\n",
        "\n",
        "    if test_type == 'means': # if we are testing difference of means\n",
        "      ss_df = pd.DataFrame(columns = ['sample_size_per_group','mde', 'alpha', 'power', 'baseline_mean', 'expected_total_weekly_traffic', 'number_of_groups', 'baseline_standard_deviation'])\n",
        "      ttc_df = pd.DataFrame(columns = ['expected weeks to reach stat-sig','mde', 'alpha', 'power', 'baseline_mean', 'expected_total_weekly_traffic', 'number_of_groups', 'baseline_standard_deviation'])\n",
        "      il_df = pd.DataFrame(columns = ['incremental lift','mde', 'alpha', 'power', 'baseline_mean', 'expected_total_weekly_traffic', 'number_of_groups', 'baseline_standard_deviation'])\n",
        "      for m in mde_list:\n",
        "        for s in baseline_stat_list:\n",
        "          effect = 0.01* m*s/baseline_standard_deviation\n",
        "\n",
        "          ss = tt_ind_solve_power(effect_size = effect, alpha = set_alpha, \\\n",
        "                               power = desired_stat_power, ratio =1, alternative = 'two-sided')\n",
        "          ttc = ss * number_of_groups/expected_total_weekly_traffic\n",
        "          il = 0.01*m* s * expected_total_weekly_traffic\n",
        "          # row inputs must match column inputs in pd.DataFrame() instantiation\n",
        "          ss_row = [int(round(ss)), m, set_alpha, desired_stat_power, s, expected_total_weekly_traffic, number_of_groups, baseline_standard_deviation]\n",
        "          ttc_row = [round(ttc,2), m, set_alpha, desired_stat_power, s, expected_total_weekly_traffic, number_of_groups, baseline_standard_deviation]\n",
        "          il_row = [int(round(il)), m, set_alpha, desired_stat_power, s, expected_total_weekly_traffic, number_of_groups, baseline_standard_deviation]\n",
        "          ss_df.loc[len(ss_df)] = ss_row\n",
        "          ttc_df.loc[len(ttc_df)] = ttc_row\n",
        "          il_df.loc[len(il_df)] = il_row\n",
        "      ss_wide=pd.pivot(ss_df, index=['alpha','power', 'baseline_mean', 'baseline_standard_deviation', 'expected_total_weekly_traffic', 'number_of_groups'], columns = 'mde',values = 'sample_size_per_group') #Reshape from long to wide\n",
        "      ttc_wide=pd.pivot(ttc_df, index=['alpha','power', 'baseline_mean','baseline_standard_deviation', 'expected_total_weekly_traffic', 'number_of_groups', 'baseline_standard_deviation'], columns = 'mde',values = 'expected weeks to reach stat-sig') #Reshape from long to wide\n",
        "      il_wide=pd.pivot(il_df, index=['alpha','power', 'baseline_mean','baseline_standard_deviation', 'expected_total_weekly_traffic', 'number_of_groups', 'baseline_standard_deviation'], columns = 'mde',values = 'incremental lift') #Reshape from long to wide\n",
        "      ss_csv_name =  current_d+ '_'+ metric_name + \"_2sample_mean_ttest_sample_size_analysis.csv\"\n",
        "      ttc_csv_name = current_d+ '_'+ metric_name + \"_2sample_mean_ttest_test_time_analysis.csv\"\n",
        "      il_csv_name = current_d+ '_'+ metric_name + \"_2sample_mean_ttest_incremental_weekly_lift_analysis.csv\"\n",
        "\n",
        "    else: # if we are testing difference of proportions\n",
        "      ss_df = pd.DataFrame(columns = ['sample_size_per_group','mde', 'alpha', 'power', 'baseline_prop', 'expected_total_weekly_traffic', 'number_of_groups'])\n",
        "      ttc_df = pd.DataFrame(columns = ['expected weeks to reach stat-sig','mde', 'alpha', 'power', 'baseline_prop', 'expected_total_weekly_traffic', 'number_of_groups'])\n",
        "\n",
        "      il_df = pd.DataFrame(columns = ['incremental lift','mde', 'alpha', 'power', 'baseline_prop', 'expected_total_weekly_traffic', 'number_of_groups'])\n",
        "      for m in mde_list:\n",
        "        for s in baseline_stat_list:\n",
        "          effect = (0.01*m*s)/ ((s * (1-s))**0.5)\n",
        "\n",
        "          ss = zt_ind_solve_power(effect_size = effect, alpha = set_alpha, \\\n",
        "                               power = desired_stat_power, ratio =1, alternative = 'two-sided')\n",
        "\n",
        "          ttc = ss * number_of_groups/expected_total_weekly_traffic\n",
        "          il = 0.01*m* s * expected_total_weekly_traffic\n",
        "          # row inputs must match column inputs in pd.DataFrame() instantiation\n",
        "          ss_row = [int(round(ss)), m, set_alpha, desired_stat_power, s, expected_total_weekly_traffic, number_of_groups]\n",
        "          ttc_row = [round(ttc,2), m, set_alpha, desired_stat_power, s, expected_total_weekly_traffic, number_of_groups]\n",
        "          il_row = [int(round(il)), m, set_alpha, desired_stat_power, s, expected_total_weekly_traffic, number_of_groups]\n",
        "          ss_df.loc[len(ss_df)] = ss_row\n",
        "          ttc_df.loc[len(ttc_df)] = ttc_row\n",
        "          il_df.loc[len(il_df)] = il_row\n",
        "      ss_wide=pd.pivot(ss_df, index=['alpha','power', 'baseline_prop', 'expected_total_weekly_traffic','number_of_groups'], columns = 'mde',values = 'sample_size_per_group') #Reshape from long to wide\n",
        "      ttc_wide=pd.pivot(ttc_df, index=['alpha','power', 'baseline_prop', 'expected_total_weekly_traffic','number_of_groups'], columns = 'mde',values = 'expected weeks to reach stat-sig') #Reshape from long to wide\n",
        "      il_wide=pd.pivot(il_df, index=['alpha','power', 'baseline_prop', 'expected_total_weekly_traffic','number_of_groups'], columns = 'mde',values = 'incremental lift') #Reshape from long to wide\n",
        "      ss_csv_name = current_d+ '_'+ metric_name + \"_2sample_proportion_ztest_sample_size_analysis.csv\"\n",
        "      ttc_csv_name = current_d+ '_'+ metric_name + \"_2sample_proportion_ztest_test_time_analysis.csv\"\n",
        "      il_csv_name = current_d+ '_'+ metric_name + \"_2sample_proportion_ztest_incremental_weekly_lift_analysis.csv\"\n",
        "\n",
        "    ss_wide.to_csv(ss_csv_name) #write analysis to csv\n",
        "    ttc_wide.to_csv(ttc_csv_name) #write analysis to csv\n",
        "    il_wide.to_csv(il_csv_name) #write analysis to csv\n",
        "    print(\"\\nAnalysis completed! Please see csv for required sample size  for each group and weeks-to-test. \\n\\n\\\n",
        "    Note: This program utilizes a two sample z-test for differences in proportions and a two sample t-test for a difference in means\")\n",
        "start = datetime.now()\n",
        "vtp = validate_test_parameters()\n",
        "sample_size(vtp)\n",
        "end = datetime.now()\n",
        "ttc = end - start\n",
        "print(\"\\nExecution time: \" + str(ttc))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Code to Refresh Directory\n",
        "#code to delete all files in directory\n",
        "import os\n",
        "for filename in os.listdir(os.getcwd()):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        file_path = os.path.join(os.getcwd(), filename)\n",
        "        #os.remove(file_path) #uncomment to delete csv files in current directory (start over)"
      ],
      "metadata": {
        "id": "3WJsvLxUfa4d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}